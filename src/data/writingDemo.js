export const WRITING_DEMO = {
  fileName: "demo_policy_argument_v1.md",
  text: `Title: Should Universities Use AI Proctoring?

AI proctoring software is becoming common in online courses because it promises fairer exams and easier monitoring at scale. The systems can track eye movement, background noise, browser activity, and identity checks in ways a human proctor cannot. Supporters argue this prevents cheating, protects grade integrity, and allows schools to offer flexible online assessments without sacrificing rigor.

At the same time, critics argue that AI proctoring treats all students as suspicious by default. Students with unstable internet, shared living spaces, disabilities, or test anxiety may be flagged at higher rates, which can turn technical friction into academic penalties. Even when a flag does not lead to formal punishment, it can still create stress and reduce trust between students and institutions.

Universities therefore face a tradeoff between scale efficiency and procedural fairness. A stronger policy would likely combine limited AI monitoring with transparent review processes, appeal rights, and alternative assessment formats. The core question is not whether schools should ban or adopt the technology outright, but under what safeguards its use can be justified.`,
};
